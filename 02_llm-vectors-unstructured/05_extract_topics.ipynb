{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e435069-eea4-41d2-824c-ff43c585822a",
   "metadata": {},
   "source": [
    "# Extract Topics\n",
    "\n",
    "In the last lesson, you built a graph using metadata to understand the course content and the relationships between the content and lessons.\n",
    "\n",
    "In this lesson, you will add topics from the unstructured lesson content to the graph.\n",
    "\n",
    "## Topics\n",
    "\n",
    "Topics are a way to categorize and organize content. You can use topics to help users find relevant content, recommend related content, and understand the relationships between different pieces of content. For example, you can find similar lessons based on their topics.\n",
    "\n",
    "There are many ways to extract topics from unstructured text. You could use an LLM and ask it to summarize the topics from the text. A more straightforward approach is to identify all the nouns in the text and use them as topics.\n",
    "\n",
    "To hold the topic data, you should extend the data model to include a new node type, Topic, and a new relationship, `MENTIONS`.\n",
    "\n",
    "<img \n",
    "    src=\"https://graphacademy.neo4j.com/courses/llm-vectors-unstructured/3-unstructured-data/6-extract-topics/images/graphacademy-lessons-paragraph-topic.svg\" \n",
    "    alt=\"Data Model\"\n",
    "    style=\"width: 50%; height: auto; display: block; margin: 0 auto;\"\n",
    "/>\n",
    "\n",
    "### Extract nouns\n",
    "The Python NLP (natural language processing) library, [textblob](https://textblob.readthedocs.io/en/dev/), can extract noun phrases from text. You will use it to extract the topics from the lesson content.\n",
    "\n",
    "You may find changing the default [Noun Phrase Chunker](https://textblob.readthedocs.io/en/dev/advanced_usage.html) used by TextBlob improves results for your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b5efa8-9a6a-4aac-989b-fe1cb7975ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!uv pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a756a1a-d467-4433-beba-27afc8b7a662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['extract topics', 'textblob']\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "phrase = \"You can extract topics from phrases using TextBlob\"\n",
    "\n",
    "topics = TextBlob(phrase).noun_phrases\n",
    "\n",
    "print(topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba04dc39-4fca-4ebd-bdfb-34de565428d4",
   "metadata": {},
   "source": [
    "### Update the Graph\n",
    "\n",
    "First, update the get_course_data function to extract topics from the lesson content. Add the topics to the data dictionary using the TextBlob.noun_phrases method:\n",
    "\n",
    "```python\n",
    "from textblob import TextBlob\n",
    "\n",
    "def get_course_data(llm, chunk):\n",
    "    data = {}\n",
    "\n",
    "    path = chunk.metadata['source'].split(os.path.sep)\n",
    "\n",
    "    data['course'] = path[-6]\n",
    "    data['module'] = path[-4]\n",
    "    data['lesson'] = path[-2]\n",
    "    data['url'] = f\"https://graphacademy.neo4j.com/courses/{data['course']}/{data['module']}/{data['lesson']}\"\n",
    "    data['text'] = chunk.page_content\n",
    "    data['embedding'] = get_embedding(llm, data['text'])\n",
    "    data['topics'] = TextBlob(data['text']).noun_phrases\n",
    "\n",
    "    return data\n",
    "```\n",
    "\n",
    "Next, update the create_chunk function to add the topics to the graph:\n",
    "\n",
    "```python\n",
    "def create_chunk(tx, data):\n",
    "    tx.run(\"\"\"\n",
    "        MERGE (c:Course {name: $course})\n",
    "        MERGE (c)-[:HAS_MODULE]->(m:Module{name: $module})\n",
    "        MERGE (m)-[:HAS_LESSON]->(l:Lesson{name: $lesson, url: $url})\n",
    "        MERGE (l)-[:CONTAINS]->(p:Paragraph{text: $text})\n",
    "        WITH p\n",
    "        CALL db.create.setNodeVectorProperty(p, \"embedding\", $embedding)\n",
    "           \n",
    "        FOREACH (topic in $topics |\n",
    "            MERGE (t:Topic {name: topic})\n",
    "            MERGE (p)-[:MENTIONS]->(t)\n",
    "        )\n",
    "        \"\"\", \n",
    "        data\n",
    "        )\n",
    "```\n",
    "\n",
    "Full code:\n",
    "\n",
    "```python\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from openai import OpenAI\n",
    "from neo4j import GraphDatabase\n",
    "from textblob import TextBlob\n",
    "\n",
    "COURSES_PATH = \"llm-vectors-unstructured/data/asciidoc\"\n",
    "\n",
    "loader = DirectoryLoader(COURSES_PATH, glob=\"**/lesson.adoc\", loader_cls=TextLoader)\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "def get_embedding(llm, text):\n",
    "    response = llm.embeddings.create(\n",
    "            input=text,\n",
    "            model=\"text-embedding-ada-002\"\n",
    "        )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def get_course_data(llm, chunk):\n",
    "    data = {}\n",
    "\n",
    "    path = chunk.metadata['source'].split(os.path.sep)\n",
    "\n",
    "    data['course'] = path[-6]\n",
    "    data['module'] = path[-4]\n",
    "    data['lesson'] = path[-2]\n",
    "    data['url'] = f\"https://graphacademy.neo4j.com/courses/{data['course']}/{data['module']}/{data['lesson']}\"\n",
    "    data['text'] = chunk.page_content\n",
    "    data['embedding'] = get_embedding(llm, data['text'])\n",
    "    data['topics'] = TextBlob(data['text']).noun_phrases\n",
    "\n",
    "    return data\n",
    "\n",
    "def create_chunk(tx, data):\n",
    "    tx.run(\"\"\"\n",
    "        MERGE (c:Course {name: $course})\n",
    "        MERGE (c)-[:HAS_MODULE]->(m:Module{name: $module})\n",
    "        MERGE (m)-[:HAS_LESSON]->(l:Lesson{name: $lesson, url: $url})\n",
    "        MERGE (l)-[:CONTAINS]->(p:Paragraph{text: $text})\n",
    "        WITH p\n",
    "        CALL db.create.setNodeVectorProperty(p, \"embedding\", $embedding)\n",
    "           \n",
    "        FOREACH (topic in $topics |\n",
    "            MERGE (t:Topic {name: topic})\n",
    "            MERGE (p)-[:MENTIONS]->(t)\n",
    "        )\n",
    "        \"\"\", \n",
    "        data\n",
    "        )\n",
    "\n",
    "llm = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "driver = GraphDatabase.driver(\n",
    "    os.getenv('NEO4J_URI'),\n",
    "    auth=(\n",
    "        os.getenv('NEO4J_USERNAME'),\n",
    "        os.getenv('NEO4J_PASSWORD')\n",
    "    )\n",
    ")\n",
    "driver.verify_connectivity()\n",
    "for chunk in chunks:\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        \n",
    "        session.execute_write(\n",
    "            create_chunk,\n",
    "            get_course_data(llm, chunk)\n",
    "        )\n",
    "driver.close()\n",
    "```\n",
    "\n",
    "### Query topics\n",
    "\n",
    "You can use the topics to find related lessons. For example, all the lessons that contain the topics \"semantic search\":\n",
    "\n",
    "```cypher\n",
    "MATCH (t:Topic{name:\"semantic search\"})<-[:MENTIONS]-(p:Paragraph)<-[:CONTAINS]-(l:Lesson)\n",
    "RETURN DISTINCT l.name, l.url\n",
    "```\n",
    "\n",
    "You can list the topics and the number of lessons that mention them to understand the most popular topics:\n",
    "\n",
    "```cypher\n",
    "MATCH (t:Topic)<-[:MENTIONS]-(p:Paragraph)<-[:CONTAINS]-(l:Lesson)\n",
    "RETURN t.name, COUNT(DISTINCT l) as lessons\n",
    "ORDER BY lessons DESC\n",
    "```\n",
    "\n",
    "By adding topics to the graph, you can use them to find related content.\n",
    "\n",
    "Topics are also universal and can be used to find related content across content from different sources. For example, if you added technical documentation to this graph, you could use the topics to find related lessons and documentation.\n",
    "\n",
    "Combining data from different sources and understanding their relationships is the starting point for creating a knowledge graph.\n",
    "\n",
    "When you have added topics to the graph, click Complete to finish this lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d56bc6-25aa-4c5c-9951-121482baca7e",
   "metadata": {},
   "source": [
    "# Expand the Graph\n",
    "\n",
    "In this optional challenge, you can extend the graph with additional data.\n",
    "\n",
    "## All Courses\n",
    "\n",
    "Currently, the graph contains data from a single course, llm-fundamentals, you can download the [lesson files for all the courses](https://data.neo4j.com/llm-vectors-unstructured/courses.zip?_gl=1*14in91n*_gcl_au*MjEzNTI4NjkxNy4xNzU3MjU4NDMzLjc4MDQ1OTczLjE3NTg0MTY3NjUuMTc1ODQxNjc2NA..*_ga*MTkzMzgxNTk1LjE3NTcyNTg0MzQ.*_ga_DL38Q8KGQC*czE3NjMxNzE3NTIkbzQ0JGcxJHQxNzYzMTc1ODc5JGo0NiRsMCRoMA..*_ga_DZP8Z65KK4*czE3NjMxNzE3NTIkbzQ0JGcxJHQxNzYzMTc1ODc5JGo0NiRsMCRoMA..).\n",
    "\n",
    "1. Download the content for all the courses - [data.neo4j.com/llm-vectors-unstructured/courses.zip](https://data.neo4j.com/llm-vectors-unstructured/courses.zip?_gl=1*14in91n*_gcl_au*MjEzNTI4NjkxNy4xNzU3MjU4NDMzLjc4MDQ1OTczLjE3NTg0MTY3NjUuMTc1ODQxNjc2NA..*_ga*MTkzMzgxNTk1LjE3NTcyNTg0MzQ.*_ga_DL38Q8KGQC*czE3NjMxNzE3NTIkbzQ0JGcxJHQxNzYzMTc1ODc5JGo0NiRsMCRoMA..*_ga_DZP8Z65KK4*czE3NjMxNzE3NTIkbzQ0JGcxJHQxNzYzMTc1ODc5JGo0NiRsMCRoMA..)\n",
    "\n",
    "2. Update the graph with the additional course data\n",
    "\n",
    "3. Explore the graph and find the connections between the courses\n",
    "\n",
    "## Additional metadata\n",
    "\n",
    "While the course content is unstructured, it contains metadata you can extract and include in the graph.\n",
    "\n",
    "Examples include:\n",
    "\n",
    "    The course title is the first level 1 heading in the file - = Course Title\n",
    "\n",
    "    Level 2 headings denote section titles - == Section Title\n",
    "\n",
    "    The lessons include parameters in the format :parameter: value at the top of the file, such as:\n",
    "\n",
    "        :type: - the type of lesson (e.g. lesson, challenge, quiz)\n",
    "\n",
    "        :order: - the order of the lesson in the module\n",
    "\n",
    "        :optional: - whether the lesson is optional\n",
    "\n",
    "Explore the course content and see what other data you can extract and include in the graph. You may also find that the content could be split into different nodes, such as sections, which may give you more accurate results.\n",
    "\n",
    "When you are ready click Move On to Continue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
