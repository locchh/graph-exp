{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "557e37a0-1f15-4e7c-9242-cf759da6af25",
   "metadata": {},
   "source": [
    "# Unstructured data\n",
    "\n",
    "## Structured and Unstructured Data\n",
    "\n",
    "As you have learned in previous lessons, a key challenge in data science is making sense of unstructured data. In this lesson, you will explore a strategy for storing unstructured data in a graph.\n",
    "\n",
    "Vector indexes and embeddings go some way to allow you to search and query unstructured data, *but they are not a complete solution. You can use the metadata surrounding the unstructured data to help make sense of it.*\n",
    "\n",
    "Imagine the following use case. You want to analyze customer emails to:\n",
    "\n",
    "- Understand the customer sentiment (are they happy or unhappy?)\n",
    "\n",
    "- Identify any products or services\n",
    "\n",
    "You could represent this data in a graph of `Email`, `Customer`, and `Product` nodes.\n",
    "\n",
    "<img \n",
    "    src=\"https://graphacademy.neo4j.com/courses/llm-vectors-unstructured/3-unstructured-data/1-structured-unstructured/images/email-graph.svg\" \n",
    "    alt=\"Data Model\"\n",
    "    style=\"width: 50%; height: auto; display: block; margin: 0 auto;\"\n",
    "/>\n",
    "\n",
    "An import for this process would have to:\n",
    "\n",
    "1. Extract the email metadata (date, sender, recipient, subject)\n",
    "\n",
    "2. Embed the email text\n",
    "\n",
    "3. Extract the customer sentiment using a vector index\n",
    "\n",
    "4. Search for references to products or services in the email text\n",
    "\n",
    "By importing the unstructured data into a graph, you can use the known relationships between the data to help make sense of it.\n",
    "\n",
    "For example, you could use the graph to answer questions like:\n",
    "\n",
    "- What products are customers talking about positively in their emails?\n",
    "\n",
    "- Are there times in the year when customers are more likely to complain?\n",
    "\n",
    "- What are customers saying about a particular product?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a8dde5-bf79-4a4b-b883-7e02d324e6d8",
   "metadata": {},
   "source": [
    "## Course data\n",
    "\n",
    "During this module, you will use Python and LangChain to import the text of a GraphAcademy course into Neo4j.\n",
    "\n",
    "GraphAcademy represents courses as a graph of Course, Module, and Lesson nodes. A course has modules, and a module has lessons.\n",
    "\n",
    "A simplistic view of the graph would look like this:\n",
    "\n",
    "<img \n",
    "    src=\"https://graphacademy.neo4j.com/courses/llm-vectors-unstructured/3-unstructured-data/1-structured-unstructured/images/graphacademy-lessons.svg\" \n",
    "    alt=\"Data Model\"\n",
    "    style=\"width: 50%; height: auto; display: block; margin: 0 auto;\"\n",
    "/>\n",
    "\n",
    "The [GraphAcademy course content](https://github.com/neo4j-graphacademy/courses) is in a public GitHub repository. We write courses in plain text [AsciiDoc](https://asciidoc.org/) that is parsed and displayed on the GraphAcademy website.\n",
    "\n",
    "The course content is unstructured, but you can make sense of it by using the metadata (the course structure), embeddings, and vector indexes\n",
    "\n",
    "View [this lesson’s content on GitHub](https://github.com/neo4j-graphacademy/courses/blob/main/asciidoc/courses/llm-vectors-unstructured/modules/3-unstructured-data/lessons/1-structured-unstructured/lesson.adoc?plain=1) and note the following:\n",
    "\n",
    "    1. The lesson content is written in plain text and is unstructured.\n",
    "\n",
    "    2. The file name is lesson.adoc.\n",
    "\n",
    "    3. All lessons have the same file name.\n",
    "\n",
    "    The directory structure denotes the course (llm-vectors-unstructured), module (3-unstructured-data), and lesson (1-structured-unstructured).\n",
    "\n",
    "You will use these files and directory structure to create the graph of the course content. Tree structure:\n",
    "\n",
    "    asciidoc - contains all the course content in ascidoc format\n",
    "\n",
    "        courses - the course content\n",
    "\n",
    "            llm-fundamentals - the course name\n",
    "\n",
    "                modules - contains numbered directories for each module\n",
    "\n",
    "                    01-name - the module name\n",
    "\n",
    "                        lessons - contains numbered directories for each lesson\n",
    "\n",
    "                            01-name - the lesson name\n",
    "\n",
    "                                lesson.adoc - the lesson content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d9180d-3f03-40d5-8013-1cbd32a047a0",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "\n",
    "When dealing with large amounts of data, breaking it into smaller, more manageable parts is helpful. This process is called chunking.\n",
    "\n",
    "Smaller pieces of data are easier to work with and process. Embedding models also have size (token) limits and can only handle a certain amount of data.\n",
    "\n",
    "Embedding large amounts of text may also be less valuable. For example, if you are trying to find a document that references a specific topic, the meaning maybe lost in the whole document. Instead, you may only need the paragraph or sentence that contains the relevant information. Conversely, small amounts of data may not contain enough context to be useful.\n",
    "\n",
    "In this lesson, you will explore strategies for chunking and storing data in a graph.\n",
    "\n",
    "### Strategies\n",
    "\n",
    "There are countless strategies for splitting data into chunks, and the best approach depends on the data and the problem you are trying to solve.\n",
    "\n",
    "It may be that the unstructured data you are working with is already in a format that is easy to split. For example, if you were looking to chunk an API’s technical documentation, you could split the data by method, endpoint, or parameter.\n",
    "\n",
    "Alternatively, you may be working with a collection of unrelated PDF documents, and splitting by section, paragraph, or sentence may be the only choice.\n",
    "\n",
    "Strategies for chunking data include:\n",
    "\n",
    "- **Size** - Splitting data into equal-sized chunks.\n",
    "\n",
    "- **Word, Sentence, Paragraph** - Breaking down text data into individual sections.\n",
    "\n",
    "- **N-Grams** - Creating chunks of n consecutive words or characters.\n",
    "\n",
    "- **Topic Segmentation** - Dividing text into sections based on topic changes.\n",
    "\n",
    "- **Event Detection** - Identifying specific events or activities.\n",
    "\n",
    "- **Semantic Segmentation** - Dividing data regions with different semantic meanings (objects, background, etc).\n",
    "\n",
    "It may also be helpful to combine multiple strategies. For example, you could split a document into paragraphs and then further split each paragraph into topic changes - this would allow you to store and query the data at different levels of granularity.\n",
    "\n",
    "### Storing Chunks\n",
    "\n",
    "How you store the chunks depends on the data, what the chunks represent, and how you intend to use the data.\n",
    "\n",
    "It is a good idea to name the nodes and relationships in a way that makes it easy to understand the data and how it is related. For example, if you split a set of documents by paragraph, you could name the nodes `Documents` and `Paragraph` with a relationship `CONTAINS`. Alternatively, if you split a document by an arbitrary size value or character, you may simply use the node label `Chunk`.\n",
    "\n",
    "You can store embeddings for individual chunks and create relationships between chunks to capture context and relationships.\n",
    "\n",
    "You may also want to store metadata about the chunks, such as the position in the original data, the size, and any other relevant information.\n",
    "\n",
    "When storing the course content, you will create a node for each `Paragraph` chunk and a relationship `CONTAINS` between the `Lesson` and `Paragraph` nodes.\n",
    "\n",
    "<img \n",
    "    src=\"https://graphacademy.neo4j.com/courses/llm-vectors-unstructured/3-unstructured-data/2-chunking/images/graphacademy-lessons-paragraph.svg\" \n",
    "    alt=\"Data Model\"\n",
    "    style=\"width: 50%; height: auto; display: block; margin: 0 auto;\"\n",
    "/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fd9804-b7bd-4b80-8773-8fa4aee26850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b8707-3a4f-434b-9bb6-cc985d4f7c40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
