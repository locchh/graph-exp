{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec103bb-a176-4302-8876-a1a9ef5eaa73",
   "metadata": {},
   "source": [
    "# Neo4j integration\n",
    "\n",
    "LangChain is a popular framework for building applications powered by large language models (LLMs).\n",
    "\n",
    "Integrating Neo4j with LangChain allows developers to build advanced AI applications that can reason over graph data, generate Cypher queries, and provide context-aware answers.\n",
    "\n",
    "Neo4j supports LangChain with dedicated modules and tools for working with graph databases, making it easier to build applications that leverage both LLMs and graph data.\n",
    "\n",
    "## Capabilities\n",
    "\n",
    "LangChain & Neo4j integration supports:\n",
    "\n",
    "\n",
    "- **Contextual Retrieval** - Retrieve relevant subgraphs or nodes from Neo4j to provide context for LLM-powered answers.\n",
    "\n",
    "- **Querying Graph Data with Natural Language** - Use LLMs to translate user questions into Cypher queries, enabling natural language access to graph data.\n",
    "\n",
    "- **Automated Reasoning** - Combine the reasoning abilities of LLMs with the structured relationships in Neo4j for more accurate and insightful responses.\n",
    "\n",
    "- **Conversational AI** - Build chatbots and assistants that can answer questions about complex, connected data stored in Neo4j.\n",
    "\n",
    "- **Knowledge Graph Construction** - Automatically construct knowledge graphs from unstructured data using LLMs, and store them in Neo4j for further analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e1a35-72b4-4276-a149-7c5a91cf3a2c",
   "metadata": {},
   "source": [
    "# Simple LangChain Agent\n",
    "\n",
    "\n",
    "\n",
    "Throughout this course, you will be adapting a simple LangChain agent to interact with Neo4j.\n",
    "\n",
    "You will update the agent to query a Neo4j graph database, retrieve information using RAG and GraphRAG, and dynamically generate Cypher queries based on user input.\n",
    "\n",
    "In this lesson, you will review the agents code to understand how it works.\n",
    "\n",
    "The application is a simple [LangGraph](https://www.langchain.com/langgraph) agent that has 2 steps:\n",
    "\n",
    "1. Retrieve information\n",
    "\n",
    "2. Generate an answer based on the retrieved information\n",
    "\n",
    "The code has 4 main sections:\n",
    "\n",
    "1. Create an LLM and Prompt\n",
    "\n",
    "2. Define the application state\n",
    "\n",
    "3. Create the application workflow\n",
    "\n",
    "4. Invoke the application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d59f3bf-1cb9-474d-b5e0-2b24ff8202b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Sunny skies, raining overnight.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "# Initialize the LLM\n",
    "model = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "\n",
    "# Create a prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[dict]\n",
    "    answer: str\n",
    "\n",
    "# Define functions for each step in the application\n",
    "\n",
    "# Retrieve context \n",
    "def retrieve(state: State):\n",
    "    context = [\n",
    "        {\"location\": \"London\", \"weather\": \"Cloudy, sunny skies later\"},\n",
    "        {\"location\": \"San Francisco\", \"weather\": \"Sunny skies, raining overnight.\"},\n",
    "    ]\n",
    "    return {\"context\": context}\n",
    "\n",
    "# Generate the answer based on the question and context\n",
    "def generate(state: State):\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": state[\"context\"]})\n",
    "    response = model.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# Define application steps\n",
    "workflow = StateGraph(State).add_sequence([retrieve, generate])\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "app = workflow.compile()\n",
    "\n",
    "# Run the application\n",
    "question = \"What is the weather in San Francisco?\"\n",
    "response = app.invoke({\"question\": question})\n",
    "print(\"Answer:\", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce8f0f-69bc-4e7a-bcda-0c256a0672f1",
   "metadata": {},
   "source": [
    "# Neo4jGraph\n",
    "\n",
    "\n",
    "You can query Neo4j from a LangChain application using the [Neo4jGraph](https://python.langchain.com/api_reference/neo4j/graphs/langchain_neo4j.graphs.neo4j_graph.Neo4jGraph.html) class. The `Neo4jGraph` class acts as the connection to the database when using other LangChain components, such as retrievers and agents.\n",
    "\n",
    "In this lesson, you will modify the simple LangChain agent to be able to answer questions about a graph database schema.\n",
    "\n",
    "The database contains information about movies, actors, and user ratings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591c76a7-6d0b-4240-9794-7327454294c3",
   "metadata": {},
   "source": [
    "## Query Neo4j\n",
    "\n",
    "To query Neo4j you need to:\n",
    "\n",
    "1. Create a Neo4jGraph instance and connect to a database\n",
    "\n",
    "2. Run a Cypher statement to get data from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff2d233e-fef7-4b9d-bc14-9bb24645a6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3073d6a6-f8e1-42d3-94c0-3cf9ce5726f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_neo4j import Neo4jGraph\n",
    "\n",
    "# Create Neo4jGraph instance\n",
    "graph = Neo4jGraph(\n",
    "    url=os.getenv(\"NEO4J_URI\"),\n",
    "    username=os.getenv(\"NEO4J_USERNAME\"), \n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e066aea9-e866-4440-9156-eb535b8ee86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'actor': 'Jim Varney', 'role': 'Slinky Dog (voice)'}, {'actor': 'Tim Allen', 'role': 'Buzz Lightyear (voice)'}, {'actor': 'Tom Hanks', 'role': 'Woody (voice)'}, {'actor': 'Don Rickles', 'role': 'Mr. Potato Head (voice)'}]\n"
     ]
    }
   ],
   "source": [
    "# Run a query and print the result\n",
    "result = graph.query(\"\"\"\n",
    "MATCH (m:Movie {title: \"Toy Story\"})<-[a:ACTED_IN]-(p:Person)\n",
    "RETURN p.name AS actor, a.role AS role\n",
    "\"\"\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3296fd5-237b-48d0-8160-b92c82cd42af",
   "metadata": {},
   "source": [
    "## Schema\n",
    "\n",
    "You are going to modify the agent to retrieve the database schema and add it to the context.\n",
    "\n",
    "You can view the database schema using the Cypher query\n",
    "\n",
    "```cypher\n",
    "CALL db.schema.visualization()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e018dbab-2bd0-4f2d-925b-b9e6ecc78168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: The graph is structured with nodes and relationships. Here is a summary of the structure:\n",
      "\n",
      "Nodes:\n",
      "1. `Movie`: Contains an index `plotEmbedding` and a uniqueness constraint on `movieId`.\n",
      "2. `User`: Has a uniqueness constraint on `userId`.\n",
      "3. `Actor`: No specific indexes or constraints.\n",
      "4. `Director`: No specific indexes or constraints.\n",
      "5. `Genre`: Has a uniqueness constraint on `name`.\n",
      "6. `Person`: Has a uniqueness constraint on `tmdbId`.\n",
      "\n",
      "Relationships:\n",
      "1. `ACTED_IN`: Connects `Person` or `Actor` or `Director` nodes to `Movie` nodes.\n",
      "2. `RATED`: Connects `User` nodes to `Movie` nodes.\n",
      "3. `DIRECTED`: Connects `Actor` or `Director` or `Person` nodes to `Movie` nodes.\n",
      "4. `IN_GENRE`: Connects `Movie` nodes to `Genre` nodes.\n",
      "\n",
      "Each relationship describes an interaction or association between the different types of nodes, such as acting in or directing a movie, rating a movie, or categorizing a movie by genre.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "\n",
    "# Connect to Neo4j\n",
    "graph = Neo4jGraph(\n",
    "    url=os.getenv(\"NEO4J_URI\"),\n",
    "    username=os.getenv(\"NEO4J_USERNAME\"), \n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    ")\n",
    "\n",
    "# Initialize the LLM\n",
    "model = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "\n",
    "# Create a prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[dict]\n",
    "    answer: str\n",
    "\n",
    "# Define functions for each step in the application\n",
    "\n",
    "# Retrieve context \n",
    "def retrieve(state: State):\n",
    "    context = graph.query(\"CALL db.schema.visualization()\")\n",
    "    return {\"context\": context}\n",
    "\n",
    "# Generate the answer based on the question and context\n",
    "def generate(state: State):\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": state[\"context\"]})\n",
    "    response = model.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# Define application steps\n",
    "workflow = StateGraph(State).add_sequence([retrieve, generate])\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "app = workflow.compile()\n",
    "\n",
    "# Run the application\n",
    "question = \"How is the graph structured?\"\n",
    "response = app.invoke({\"question\": question})\n",
    "print(\"Answer:\", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4910b4-021f-4f80-9fc4-3a8817cb09ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
