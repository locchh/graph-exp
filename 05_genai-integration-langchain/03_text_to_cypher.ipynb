{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cca3d278-278e-493c-90f9-ce9dda5b5149",
   "metadata": {},
   "source": [
    "# Text to Cypher\n",
    "\n",
    "Vector retrievers are great for finding relevant data based on semantic similarity.\n",
    "\n",
    "To answer more specific questions, you may need to perform more complex queries to find data relating to specific nodes, relationships, or properties.\n",
    "\n",
    "Text to Cypher allows you to convert natural language queries into Cypher queries that can be executed against the graph.\n",
    "\n",
    "In this module, you will:\n",
    "\n",
    "- Use the Cypher QA (question-answering) chain to query the graph using natural language queries.\n",
    "\n",
    "- Create a custom Cypher generation prompt include specific instructions and examples queries.\n",
    "\n",
    "- Explore how restricting the schema can support more focused queries.\n",
    "\n",
    "- Add a text to Cypher retriever to a LangChain agent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092ba860-0071-4d6c-a727-6bd217510668",
   "metadata": {},
   "source": [
    "# Cypher QA Chain\n",
    "\n",
    "The LangChain [GraphCypherQAChain](https://python.langchain.com/api_reference/neo4j/chains/langchain_neo4j.chains.graph_qa.cypher.GraphCypherQAChain.html):\n",
    "\n",
    "1. Accepts a question.\n",
    "\n",
    "2. Converts the question into a Cypher query using the graph schema.\n",
    "\n",
    "3. Executes the query\n",
    "\n",
    "4. Uses the result to generate an answer.\n",
    "\n",
    "If asked the question \"What year was the movie Babe released?\", the chain will generate messages like:\n",
    "\n",
    "```\n",
    "[human]\n",
    "What year was the movie Babe released?\n",
    "[system]\n",
    "Generate a Cypher query based on this question and this graph schema.\n",
    "[assistant]\n",
    "MATCH (m:Movie)\n",
    "WHERE m.title = 'Babe'\n",
    "RETURN m.released\n",
    "\n",
    "The Cypher query is the executed and the result returned.\n",
    "\n",
    "[system]\n",
    "Generate an answer based on these results [{m.released_year: 1995}].\n",
    "[assistant]\n",
    "The movie Babe was released in 1995.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f277ca9-4bb6-4965-b95a-c2c6384fef46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mcypher\n",
      "MATCH (:Movie)-[:IN_GENRE]->(:Genre {name: \"Sci-Fi\"})\n",
      "RETURN count(*) AS sciFiMovieCount\n",
      "\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'sciFiMovieCount': 5}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "There are 5 movies in the Sci-Fi genre.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain_neo4j import GraphCypherQAChain\n",
    "\n",
    "# Initialize the LLM\n",
    "model = init_chat_model(\n",
    "    \"gpt-4o\", \n",
    "    model_provider=\"openai\"\n",
    ")\n",
    "\n",
    "# Connect to Neo4j\n",
    "graph = Neo4jGraph(\n",
    "    url=os.getenv(\"NEO4J_URI\"),\n",
    "    username=os.getenv(\"NEO4J_USERNAME\"), \n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    ")\n",
    "\n",
    "# Create the Cypher QA chain\n",
    "cypher_qa = GraphCypherQAChain.from_llm(\n",
    "    graph=graph, \n",
    "    llm=model, \n",
    "    allow_dangerous_requests=True,\n",
    "    verbose=True, \n",
    ")\n",
    "\n",
    "# Invoke the chain\n",
    "question = \"How many movies are in the Sci-Fi genre?\"\n",
    "response = cypher_qa.invoke({\"query\": question})\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b2d4bc-9c12-496b-a53b-90d1cbe50e22",
   "metadata": {},
   "source": [
    "## Allow Dangerous Requests\n",
    "\n",
    "You are trusting the generation of Cypher to the LLM. It may generate invalid Cypher queries that could corrupt data in the graph or provide access to sensitive information.\n",
    "\n",
    "You have to opt-in to this risk by setting the `allow_dangerous_requests` flag to `True`.\n",
    "\n",
    "In a production environment, you should ensure that access to data is limited, and sufficient security is in place to prevent malicious queries. This could include the use of a [read only user](https://neo4j.com/docs/operations-manual/current/authentication-authorization/manage-users/?_gl=1*xiizkq*_gcl_au*MjEzNTI4NjkxNy4xNzU3MjU4NDMzLjc4MDQ1OTczLjE3NTg0MTY3NjUuMTc1ODQxNjc2NA..*_ga*MTkzMzgxNTk1LjE3NTcyNTg0MzQ.*_ga_DL38Q8KGQC*czE3NjMyNjQ0MzMkbzQ3JGcxJHQxNzYzMzAzNDg0JGo2MCRsMCRoMA..*_ga_DZP8Z65KK4*czE3NjMyNjQ0MzMkbzQ3JGcxJHQxNzYzMzAzNDg0JGo2MCRsMCRoMA..) or [role based access control](https://neo4j.com/docs/operations-manual/current/authentication-authorization/manage-privileges/?_gl=1*xiizkq*_gcl_au*MjEzNTI4NjkxNy4xNzU3MjU4NDMzLjc4MDQ1OTczLjE3NTg0MTY3NjUuMTc1ODQxNjc2NA..*_ga*MTkzMzgxNTk1LjE3NTcyNTg0MzQ.*_ga_DL38Q8KGQC*czE3NjMyNjQ0MzMkbzQ3JGcxJHQxNzYzMzAzNDg0JGo2MCRsMCRoMA..*_ga_DZP8Z65KK4*czE3NjMyNjQ0MzMkbzQ3JGcxJHQxNzYzMzAzNDg0JGo2MCRsMCRoMA..).\n",
    "\n",
    "## Generated Cypher\n",
    "\n",
    "The LLM may not always understand the graph schema or the question correctly. This can lead to the generated Cypher queries being incorrect or inefficient.\n",
    "\n",
    "You will explore different ways to improve the quality of the generated Cypher queries in the next lesson.\n",
    "\n",
    "## Cypher LLM\n",
    "\n",
    "You can use different LLMs to generate the Cypher query and the answer.\n",
    "\n",
    "This is useful as the requirements for generating a Cypher query maybe different from generating answer.\n",
    "\n",
    "Modify the program to include a different LLM for the Cypher query generation:\n",
    "\n",
    "```cypher\n",
    "cypher_model = init_chat_model(\n",
    "    \"gpt-4o\", \n",
    "    model_provider=\"openai\",\n",
    "    temperature=0.0\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db6903a-463c-4e53-b46f-bcb89a71eb85",
   "metadata": {},
   "source": [
    "# Cypher Generation\n",
    "\n",
    "To improve the accuracy of the generated Cypher queries you can customize the generation prompt for your data requirements.\n",
    "\n",
    "In this lesson, you will learn how to provide specific instructions and examples queries to improve Cypher query generation.\n",
    "\n",
    "## Prompt\n",
    "\n",
    "You can provide a custom prompt to the GraphCypherQAChain. You can tailor the prompt to your use case to generate more accurate Cypher queries.\n",
    "\n",
    "```python\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "# Cypher template\n",
    "cypher_template = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Note: Do not include any explanations or apologies in your responses.\n",
    "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "Do not include any text except the generated Cypher statement.\n",
    "\n",
    "The question is:\n",
    "{question}\"\"\"\n",
    "\n",
    "cypher_prompt = PromptTemplate(\n",
    "    input_variables=[\"schema\", \"question\"], \n",
    "    template=cypher_template\n",
    ")\n",
    "```\n",
    "\n",
    "The prompt includes instructions for generating Cypher queries including parameters for the `schema`, and `question`. When invoked the `GraphCypherQAChain` will insert the `schema` and `question` parameters into the prompt.\n",
    "\n",
    "Add the custom prompt to the `GraphCypherQAChain`:\n",
    "\n",
    "```python\n",
    "cypher_qa = GraphCypherQAChain.from_llm(\n",
    "    graph=graph, \n",
    "    llm=model, \n",
    "    cypher_llm=cypher_model,\n",
    "    cypher_prompt=cypher_prompt,\n",
    "    allow_dangerous_requests=True,\n",
    "    verbose=True,\n",
    ")\n",
    "```\n",
    "\n",
    "## Specific instructions\n",
    "\n",
    "To manage specific data or business rules, you can provide specific instructions to the LLM when generating the Cypher.\n",
    "\n",
    "For example, movie titles that start with \"The\" are stored in the graph as \"Matrix, The\" instead of \"The Matrix\".\n",
    "\n",
    "Asking the LLM to generate Cypher queries without this information will result in no data being returned.\n",
    "\n",
    "```\n",
    "[user]\n",
    "Who acted in the movie The Matrix?\n",
    "\n",
    "[assistant]\n",
    "I don't know.\n",
    "```\n",
    "\n",
    "Update the cypher_template to include a specific instruction to the LLM to handle this case:\n",
    "\n",
    "    For movie titles that begin with \"The\", move \"the\" to the end,\n",
    "    for example \"The 39 Steps\" becomes \"39 Steps, The\".\n",
    "\n",
    "```\n",
    "# Cypher template with additional instructions\n",
    "cypher_template = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "For movie titles that begin with \"The\", move \"the\" to the end, for example \"The 39 Steps\" becomes \"39 Steps, The\".\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Note: Do not include any explanations or apologies in your responses.\n",
    "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "Do not include any text except the generated Cypher statement.\n",
    "\n",
    "The question is:\n",
    "{question}\"\"\"\n",
    "```\n",
    "\n",
    "## Examples\n",
    "\n",
    "You can provide examples of questions and relevant Cypher queries to help the LLM generate more accurate Cypher queries.\n",
    "\n",
    "Questions that relate to movies ratings often generate ambiguous or incorrect Cypher. This is because the rating is a property of the RATED relationship, and the Movie node also includes a imdbRating property.\n",
    "\n",
    "Cypher examples should describe the query and the expected Cypher query, for example:\n",
    "\n",
    "```\n",
    "Question: Get user ratings?\n",
    "Cypher: MATCH (u:User)-[r:RATED]->(m:Movie)\n",
    "        WHERE u.name = \"User name\"\n",
    "        RETURN r.rating AS userRating\n",
    "```\n",
    "\n",
    "Update the `cypher_template` to include the examples relating to movie ratings:\n",
    "\n",
    "```\n",
    "# Cypher template with examples\n",
    "cypher_template = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "For movie titles that begin with \"The\", move \"the\" to the end, for example \"The 39 Steps\" becomes \"39 Steps, The\".\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "Examples:\n",
    "1. Question: Get user ratings?\n",
    "   Cypher: MATCH (u:User)-[r:RATED]->(m:Movie) WHERE u.name = \"User name\" RETURN r.rating AS userRating\n",
    "2. Question: Get average rating for a movie?\n",
    "   Cypher: MATCH (m:Movie)<-[r:RATED]-(u:User) WHERE m.title = 'Movie Title' RETURN avg(r.rating) AS userRating\n",
    "\n",
    "Note: Do not include any explanations or apologies in your responses.\n",
    "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "Do not include any text except the generated Cypher statement.\n",
    "\n",
    "The question is:\n",
    "{question}\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbc9ea94-4566-4f00-a423-b89977d1cd0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (m:Movie) WHERE m.title = '39 Steps, The' RETURN m.released AS releaseDate\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I don't know the answer.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain_neo4j import GraphCypherQAChain\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "\n",
    "model = init_chat_model(\n",
    "    \"gpt-4o\", \n",
    "    model_provider=\"openai\"\n",
    ")\n",
    "\n",
    "cypher_model = init_chat_model(\n",
    "    \"gpt-4o-mini\", \n",
    "    model_provider=\"openai\",\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "graph = Neo4jGraph(\n",
    "    url=os.getenv(\"NEO4J_URI\"),\n",
    "    username=os.getenv(\"NEO4J_USERNAME\"), \n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Cypher template with examples\n",
    "cypher_template = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "For movie titles that begin with \"The\", move \"the\" to the end, for example \"The 39 Steps\" becomes \"39 Steps, The\".\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "Examples:\n",
    "1. Question: Get user ratings?\n",
    "   Cypher: MATCH (u:User)-[r:RATED]->(m:Movie) WHERE u.name = \"User name\" RETURN r.rating AS userRating\n",
    "2. Question: Get average rating for a movie?\n",
    "   Cypher: MATCH (m:Movie)<-[r:RATED]-(u:User) WHERE m.title = 'Movie Title' RETURN avg(r.rating) AS userRating\n",
    "\n",
    "Note: Do not include any explanations or apologies in your responses.\n",
    "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "Do not include any text except the generated Cypher statement.\n",
    "\n",
    "The question is:\n",
    "{question}\"\"\"\n",
    "\n",
    "\n",
    "cypher_prompt = PromptTemplate(\n",
    "    input_variables=[\"schema\", \"question\"], \n",
    "    template=cypher_template\n",
    ")\n",
    "\n",
    "cypher_qa = GraphCypherQAChain.from_llm(\n",
    "    graph=graph, \n",
    "    llm=model, \n",
    "    cypher_llm=cypher_model,\n",
    "    cypher_prompt=cypher_prompt,\n",
    "    allow_dangerous_requests=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "question = \"What was the release date of the movie The 39 Steps?\"\n",
    "response = cypher_qa.invoke({\"query\": question})\n",
    "print(response[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e992455-a825-4381-af5b-d30d40c6a6a8",
   "metadata": {},
   "source": [
    "## Genres\n",
    "\n",
    "The database contains data about movie genres.\n",
    "\n",
    "When generating more complex Cypher queries, such as those that involve genres, the LLM may not generate the correct Cypher query.\n",
    "\n",
    "These queries may require a specific example on how to retrieve genres from the graph:\n",
    "\n",
    "- What is the highest user rated movie in the Horror genre?\n",
    "\n",
    "- How many Sci-Fi movies has Tom Hanks acted in?\n",
    "\n",
    "Your challenge is to provide an example Cypher query that demonstrates how to retrieve genres from the graph.\n",
    "\n",
    "```python\n",
    "# Cypher template with examples\n",
    "cypher_template = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "For movie titles that begin with \"The\", move \"the\" to the end, for example \"The 39 Steps\" becomes \"39 Steps, The\".\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "Examples:\n",
    "1. Question: Get user ratings?\n",
    "   Cypher: MATCH (u:User)-[r:RATED]->(m:Movie) WHERE u.name = \"User name\" RETURN r.rating AS userRating\n",
    "2. Question: Get average rating for a movie?\n",
    "   Cypher: MATCH (m:Movie)<-[r:RATED]-(u:User) WHERE m.title = 'Movie Title' RETURN avg(r.rating) AS userRating\n",
    "3. Question: Get movies for a genre?\n",
    "   Cypher: MATCH ((m:Movie)-[:IN_GENRE]->(g:Genre) WHERE g.name = 'Genre Name' RETURN m.title AS movieTitle\n",
    "\n",
    "Note: Do not include any explanations or apologies in your responses.\n",
    "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "Do not include any text except the generated Cypher statement.\n",
    "\n",
    "The question is:\n",
    "{question}\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c918c66-3e6f-4079-b863-99137587a1d2",
   "metadata": {},
   "source": [
    "# Schema\n",
    "\n",
    "The LLM generates Cypher queries based on the schema of the graph. When a query is submitted, the schema is automatically read from the database and added to the prompt.\n",
    "\n",
    "In this lesson, you will learn how to restrict the schema to only include certain node labels or relationship types.\n",
    "\n",
    "Restricting the schema can help generate better Cypher by:\n",
    "\n",
    "- Reducing the complexity of the generated Cypher queries.\n",
    "\n",
    "- Helping the LLM focus on the relevant parts of the graph.\n",
    "\n",
    "- Excluding irrelevant or unwanted parts of the graph that may confuse the LLM.\n",
    "\n",
    "More generally, the more focused the schema, the better the LLM can generate Cypher queries.\n",
    "\n",
    "## Restricting the schema\n",
    "\n",
    "You can restrict the schema by either providing the `GraphCypherQAChain` with a list of node labels and relationship types to **include** or **exclude** from the schema.\n",
    "\n",
    "If you wanted to just include data about movies and their directors, you could provide the following list of node labels and relationship types to include:\n",
    "\n",
    "- Movie\n",
    "\n",
    "- DIRECTED\n",
    "\n",
    "- Director\n",
    "\n",
    "You provide the types as a list to the `include_types` parameter of the `GraphCypherQAChain`:\n",
    "\n",
    "```python\n",
    "# Create the Cypher QA chain\n",
    "cypher_qa = GraphCypherQAChain.from_llm(\n",
    "    graph=graph, \n",
    "    llm=model, \n",
    "    include_types=[\"Movie\", \"ACTED_IN\", \"Person\"],\n",
    "    allow_dangerous_requests=True,\n",
    "    verbose=True, \n",
    ")\n",
    "```\n",
    "\n",
    "When prompted with a question about movies, the LLM will only be able to respond with answers related to movies and directors.\n",
    "\n",
    "Alternatively, if you wanted to exclude ratings data, you could provide `User` and `RATED` as the types to the exclude_types parameter:\n",
    "\n",
    "```python\n",
    "# Create the Cypher QA chain\n",
    "cypher_qa = GraphCypherQAChain.from_llm(\n",
    "    graph=graph, \n",
    "    llm=model, \n",
    "    exclude_types=[\"User\", \"RATED\"],\n",
    "    allow_dangerous_requests=True,\n",
    "    verbose=True, \n",
    ")\n",
    "```\n",
    "\n",
    "How you restrict the schema will depend on the graph structure and the types of questions you want to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c904381-ab4a-4a17-9d67-7e1c86af03a5",
   "metadata": {},
   "source": [
    "# Retriever\n",
    "\n",
    "In this lesson, you will use the GraphCypherQAChain to add a text to Cypher retriever to the LangChain agent.\n",
    "\n",
    "## Text to Cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "290cc003-0f63-4294-9616-dfa762c117a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Tom Hanks has acted in \"Toy Story\" according to the provided context. However, he has also appeared in many other movies, including \"Forrest Gump,\" \"Cast Away,\" \"Saving Private Ryan,\" \"The Green Mile,\" \"Big,\" and the \"Toy Story\" sequels, among others. Please note that the context provided only lists \"Toy Story.\"\n",
      "Context: {'query': 'What movies has Tom Hanks acted in?', 'result': [{'m.title': 'Toy Story'}]}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain_neo4j import GraphCypherQAChain\n",
    "\n",
    "# Initialize the LLM\n",
    "model = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "\n",
    "# Create a prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[dict]\n",
    "    answer: str\n",
    "\n",
    "# Connect to Neo4j\n",
    "graph = Neo4jGraph(\n",
    "    url=os.getenv(\"NEO4J_URI\"),\n",
    "    username=os.getenv(\"NEO4J_USERNAME\"), \n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    ")\n",
    "\n",
    "# Create the Cypher QA chain\n",
    "cypher_qa = GraphCypherQAChain.from_llm(\n",
    "    graph=graph, \n",
    "    llm=model, \n",
    "    allow_dangerous_requests=True,\n",
    "    return_direct=True,\n",
    ")\n",
    "\n",
    "# Define functions for each step in the application\n",
    "\n",
    "# Retrieve context \n",
    "def retrieve(state: State):\n",
    "    context = cypher_qa.invoke(\n",
    "        {\"query\": state[\"question\"]}\n",
    "    )\n",
    "    return {\"context\": context}\n",
    "\n",
    "# Generate the answer based on the question and context\n",
    "def generate(state: State):\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": state[\"context\"]})\n",
    "    response = model.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# Define application steps\n",
    "workflow = StateGraph(State).add_sequence([retrieve, generate])\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "app = workflow.compile()\n",
    "\n",
    "# Run the application\n",
    "question = \"What movies has Tom Hanks acted in?\"\n",
    "response = app.invoke({\"question\": question})\n",
    "print(\"Answer:\", response[\"answer\"])\n",
    "print(\"Context:\", response[\"context\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa9136b-9703-4a64-bb89-05f9473345a4",
   "metadata": {},
   "source": [
    "## Improve the retriever\n",
    "\n",
    "Your challenge is to improve the retriever using the techniques you learned in the previous lessons, which could include:\n",
    "\n",
    "- Providing a custom prompt and specific instructions.\n",
    "\n",
    "- Including example questions and Cypher queries.\n",
    "\n",
    "- Using a different LLM model for Cypher generation.\n",
    "\n",
    "- Restricting the schema to provide more focused results.\n",
    "\n",
    "Here are some examples of more complex questions you can try:\n",
    "\n",
    "- When was the movie The Abyss released?\n",
    "\n",
    "- What is the highest grossing movie of all time?\n",
    "\n",
    "- Can you recommend a Horror movie based on user rating?\n",
    "\n",
    "- What movies scored about 4 for user rating?\n",
    "\n",
    "- What are the highest rated movies with more than 100 ratings?\n",
    "\n",
    "There is no right or wrong solution. You should experiment with different approaches to see how they affect the accuracy and relevance of the generated Cypher queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc9a93e2-0d52-416f-89fa-951fe219a90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (m:Movie) WHERE m.revenue IS NOT NULL RETURN CASE WHEN m.title STARTS WITH 'The ' THEN substring(m.title, 4) + ', The' ELSE m.title END AS movieTitle ORDER BY m.revenue DESC LIMIT 1\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'movieTitle': 'Toy Story'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: I don't know.\n",
      "Context: {'query': 'What is the highest grossing movie of all time?', 'result': \"I don't know the answer.\"}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain_neo4j import GraphCypherQAChain\n",
    "\n",
    "# Initialize the LLM\n",
    "model = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "\n",
    "# Create a prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[dict]\n",
    "    answer: str\n",
    "\n",
    "# Connect to Neo4j\n",
    "graph = Neo4jGraph(\n",
    "    url=os.getenv(\"NEO4J_URI\"),\n",
    "    username=os.getenv(\"NEO4J_USERNAME\"), \n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    ")\n",
    "\n",
    "cypher_template = \"\"\"Task:Generate Cypher statement to query a graph database.\n",
    "Instructions:\n",
    "Use only the provided relationship types and properties in the schema.\n",
    "Do not use any other relationship types or properties that are not provided.\n",
    "For movie titles that begin with \"The\", move \"the\" to the end, for example \"The 39 Steps\" becomes \"39 Steps, The\".\n",
    "Exclude NULL values when finding the highest value of a property.\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "Examples:\n",
    "1. Question: Get user ratings?\n",
    "   Cypher: MATCH (u:User)-[r:RATED]->(m:Movie) WHERE u.name = \"User name\" RETURN r.rating AS userRating\n",
    "2. Question: Get average rating for a movie?\n",
    "   Cypher: MATCH (m:Movie)<-[r:RATED]-(u:User) WHERE m.title = 'Movie Title' RETURN avg(r.rating) AS userRating\n",
    "3. Question: Get movies for a genre?\n",
    "   Cypher: MATCH ((m:Movie)-[:IN_GENRE]->(g:Genre) WHERE g.name = 'Genre Name' RETURN m.title AS movieTitle\n",
    "\n",
    "Note: Do not include any explanations or apologies in your responses.\n",
    "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "Do not include any text except the generated Cypher statement.\n",
    "\n",
    "The question is:\n",
    "{question}\"\"\"\n",
    "\n",
    "cypher_prompt = PromptTemplate(\n",
    "    input_variables=[\"schema\", \"question\"], \n",
    "    template=cypher_template\n",
    ")\n",
    "\n",
    "# Create the Cypher QA chain\n",
    "cypher_qa = GraphCypherQAChain.from_llm(\n",
    "    graph=graph, \n",
    "    llm=model, \n",
    "    cypher_prompt=cypher_prompt,\n",
    "    allow_dangerous_requests=True,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Define functions for each step in the application\n",
    "\n",
    "# Retrieve context \n",
    "def retrieve(state: State):\n",
    "    context = cypher_qa.invoke(\n",
    "        {\"query\": state[\"question\"]}\n",
    "    )\n",
    "    return {\"context\": context}\n",
    "\n",
    "# Generate the answer based on the question and context\n",
    "def generate(state: State):\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": state[\"context\"]})\n",
    "    response = model.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# Define application steps\n",
    "workflow = StateGraph(State).add_sequence([retrieve, generate])\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "app = workflow.compile()\n",
    "\n",
    "# Run the application\n",
    "question = \"What is the highest grossing movie of all time?\"\n",
    "response = app.invoke({\"question\": question})\n",
    "print(\"Answer:\", response[\"answer\"])\n",
    "print(\"Context:\", response[\"context\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
